卷积网络
首先，您将实现卷积网络中使用的几种层类型。然后，您将使用这些层在 CIFAR-10 数据集上训练一个卷积网络。
仿射层：正向
打开 cs231n/layers.py 文件并实现 affine_forward 函数。
完成后，您可以运行下面的代码来测试您的实现：
仿射层：后向
现在实现 affine_backward 函数，并使用数值梯度检查测试您的实现。
ReLU 激活：前向
在 relu_forward 函数中实现 ReLU 激活函数的前向传递，并使用下面的代码测试实现情况：
ReLU 激活：后向
现在，在 relu_backward 函数中实现 ReLU 激活函数的后向传递，并使用数值梯度检查测试实现情况：
“三明治 "层
神经网络中经常使用一些常见的层模式。例如，仿射层之后经常会有一个 ReLU 非线性层。为了简化这些常见模式，我们在 cs231n/layer_utils.py 文件中定义了几种方便层。
现在先看看 affine_relu_forward 和 affine_relu_backward 函数，然后运行下面的函数来对后向传递进行数值梯度检查：
损耗层： 软最大
现在在 cs231n/layers.py 中的 softmax_loss 函数中实现 softmax 的损耗和梯度。
您可以通过运行以下程序来确保实现的正确性：
卷积： 原始前向传递
卷积网络的核心是卷积操作。在 cs231n/layers.py 文件中，在 conv_forward_naive 函数中实现卷积层的前向传递。
在这一点上，你不必过于担心效率问题；只需以你认为最清晰的方式编写代码即可。
你可以运行下面的代码来测试你的实现：
附录：通过卷积进行图像处理
我们将设置一个包含两幅图像的输入，并手动设置过滤器来执行常见的图像处理操作（灰度转换和边缘检测）。卷积前向传递将对每张输入图像应用这些操作。然后，我们可以将结果可视化，作为正确性检查。
卷积 原始后向传递
在 cs231n/layers.py 文件中的 conv_backward_naive 函数中实现卷积操作的后向传递。同样，您不必过于担心计算效率。
完成后，运行下面的数值梯度检查来检查您的后向传递。
最大池化： 前向传递
在 cs231n/layers.py 文件中的 max_pool_forward_naive 函数中实现 max-pooling 操作的前向传递。同样，不必过于担心计算效率。
请运行以下代码检查您的实现：
Max-Pooling： 裸回传
在 cs231n/layers.py 文件中的 max_pool_backward_naive 函数中实现最大池操作的后向传递。您无需担心计算效率。
运行下面的梯度数值检查，检查你的实现：
快速图层
实现快速卷积和池化图层是一项挑战。为了免除您的痛苦，我们在 cs231n/fast_layers.py 文件中提供了卷积层和池化层的前向和后向传递的快速实现。
执行下面的单元格，保存笔记本并重新启动运行时
快速卷积的实现依赖于 Cython 扩展；要编译它，请运行下面的单元格。然后，保存 Colab 笔记本（文件 > 保存）并重启运行时（运行时 > 重启运行时）。然后，您可以从上到下重新执行前面的单元格，并跳过下面的单元格，因为编译步骤只需运行一次。
#卷积层和池化层快速版的 API 与上述天真版完全相同：前向传递接收数据、权重和参数，并生成输出和缓存对象；后向传递接收上游导数和缓存对象，并生成与数据和权重相关的梯度。
注意：只有当汇集区域不重叠并对输入进行平铺时，汇集的快速执行才能达到最佳效果。如果不满足这些条件，那么快速池化实现的速度不会比简单实现快多少。
你可以通过运行以下程序来比较这些层的原始版本和快速版本的性能：
卷积 “三明治 ”层
在 cs231n/layer_utils.py 文件中，你可以找到实现卷积网络常用模式的三明治层。运行下面的单元格来检查它们的使用情况。
多层卷积网络
现在你已经实现了所有必要的层，我们可以将它们组合成一个简单的卷积网络。
